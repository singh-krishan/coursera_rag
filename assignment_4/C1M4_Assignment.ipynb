{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Developing a RAG-based Chatbot\n",
    "---\n",
    "Welcome to your fourth assignment in the RAG course! Having acquired foundational techniques, you are now ready to embark on building a more sophisticated Retrieval-Augmented Generation (RAG) system. In this assignment, you will undertake the following tasks:\n",
    "\n",
    "- **LLM routing**: Develop functions to help categorize and identify the type of each query, creating a router that, depending on the query nature, different treatments are performed.\n",
    "- **Conditional parameter setting**: Create methods to determine if a user‚Äôs query is creative or technical. This allows the LLM to adjust its settings to give the best answer.\n",
    "- **Producing JSON Responses**: Program the LLMs to generate valid JSON responses with product information, making sure the output is organized for more processing if needed.\n",
    "- **Adding Contextual Information**: Include relevant data in queries before they are handled by the LLM.\n",
    "- **Chatbot Development**: Create a chatbot that can interact with users in a natural and efficient way, answering their questions clearly.\n",
    "\n",
    "In this assignment, you will apply the skills you've learned to integrate RAG capabilities into a RAG system that will support a ChatBot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "- [ 1 - Introduction: Your Mission at Fashion Forward Hub](#1)\n",
    "  - [ 1.1 Importing the libraries](#1-1)\n",
    "  - [ 1.2 Loading the Weaviate client](#1-2)\n",
    "- [ 2 - Understanding Fashion Forward Hub data schema](#2)\n",
    "  - [ 2.1 Products Database](#2-1)\n",
    "  - [ 2.2 FAQ Database](#2-2)\n",
    "- [ 3 - Task routing](#3)\n",
    "  - [ 3.1 Deciding if a query is FAQ or Product related](#3-1)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 3.2 Answering a FAQ question](#3-2)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 3.3 Decide the Nature of a Product-Related Question](#3-3)\n",
    "    - [ Exercise 3](#ex03)\n",
    "  - [ 3.4 Retrieving the Parameters for a Given Task](#3-4)\n",
    "    - [ Exercise 4](#ex04)\n",
    "- [ 4 - Retrieving Items Based on Metadata Inferred from a Query](#4)\n",
    "  - [ 4.1 Generate metadata](#4-1)\n",
    "    - [ Exercise 5](#ex05)\n",
    "  - [ 4.2 Loading the Weaviate Product Collection](#4-2)\n",
    "  - [ 4.3 Filtering by metadata (NOT GRADED)](#4-3)\n",
    "  - [ 4.4 Generating the retrieve items as a context (NOT GRADED)](#4-4)\n",
    "  - [ 4.5 Query on Products (NOT GRADED)](#4-5)\n",
    "- [ 5 - The Final Function!](#5)\n",
    "  - [ 5.1 The function to rule them all](#5-1)\n",
    "  - [ 5.2 The ChatBot](#5-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h4 style=\"color:black; font-weight:bold;\">USING THE TABLE OF CONTENTS</h4>\n",
    "\n",
    "JupyterLab provides an easy way for you to navigate through your assignment. It's located under the Table of Contents tab, found in the left panel, as shown in the picture below.\n",
    "\n",
    "![TOC Location](images/toc.png)\n",
    "\n",
    "---\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "- All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "- You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "- Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "- - To submit your notebook for grading, first save it by clicking the üíæ icon on the top left of the page and then click on the <span style=\"background-color: blue; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Introduction: Your Mission at Fashion Forward Hub\n",
    "---\n",
    "\n",
    "Great news! You've been brought on board by Fashion Forward Hub, an online clothing store always looking for the latest technology. They need your help to create a smart chatbot for their website. This chatbot will answer common questions, provide details about products, and help customers pick out outfits.\n",
    "\n",
    "Using what you've learned so far in this course, you'll apply your skills in Retrieval-Augmented Generation (RAG) to make this chatbot a reality. The tools and techniques you've been exploring will come together as you build a system that makes shopping easier and more fun. Get ready to show how technology can transform the customer experience at Fashion Forward Hub!\n",
    "\n",
    "<a id='1-1'></a>\n",
    "### 1.1 Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from weaviate.classes.query import Filter\n",
    "import weaviate\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'flask_app'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "import unittests\n",
    "import flask_app\n",
    "import weaviate_server\n",
    "from utils import (\n",
    "    ChatWidget,\n",
    "    generate_with_single_input,\n",
    "    generate_params_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1-2'></a>\n",
    "### 1.2 Loading the Weaviate client\n",
    "\n",
    "In this assignment you will use again the Weaviate API to load the vector database. Do not worry, you won't need to load the database. It is already given to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local(port=8079, grpc_port=50050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 `generate_params_dict` function\n",
    "\n",
    "Let's recap the function you worked in the Ungraded lab to generate a dictionary of parameters:\n",
    "\n",
    "```Python\n",
    "def generate_params_dict(\n",
    "    prompt: str, \n",
    "    temperature: float = None, \n",
    "    role = 'user',\n",
    "    top_p: float = None,\n",
    "    max_tokens: int = 500,\n",
    "    model: str = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Solve x^2 - 1 = 0', 'role': 'user', 'temperature': 1.2, 'top_p': 0.2, 'max_tokens': 500, 'model': 'meta-llama/Llama-3.2-3B-Instruct-Turbo'}\n"
     ]
    }
   ],
   "source": [
    "# An output example is\n",
    "kwargs = generate_params_dict(\"Solve x^2 - 1 = 0\", temperature = 1.2, top_p = 0.2)\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the equation x^2 - 1 = 0, we can start by adding 1 to both sides:\n",
      "\n",
      "x^2 - 1 + 1 = 0 + 1\n",
      "\n",
      "This simplifies to:\n",
      "\n",
      "x^2 = 1\n",
      "\n",
      "Next, we can take the square root of both sides:\n",
      "\n",
      "x = ‚àö1\n",
      "\n",
      "x = ¬±1\n",
      "\n",
      "So, the solutions to the equation x^2 - 1 = 0 are x = 1 and x = -1.\n"
     ]
    }
   ],
   "source": [
    "# Generating \n",
    "response = generate_with_single_input(**kwargs)\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - Understanding Fashion Forward Hub data schema\n",
    "---\n",
    "In this section, you will understand how the data is stored in Fashion Forward hub databases. \n",
    "\n",
    "There are two databases:\n",
    "\n",
    "- Product database: Contains the products and their information.\n",
    "- FAQ database: Contains the FAQ data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2-1'></a>\n",
    "### 2.1 Products Database\n",
    "\n",
    "Let's explore the products database that Fashion Forward Hub has available. To make it easier to understand, let's load it as a list of JSON files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading products data\n",
    "PRODUCTS_DATA = joblib.load('dataset/clothes_json.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'Men',\n",
       " 'masterCategory': 'Apparel',\n",
       " 'subCategory': 'Topwear',\n",
       " 'articleType': 'Shirts',\n",
       " 'baseColour': 'Navy Blue',\n",
       " 'season': 'Fall',\n",
       " 'year': 2011.0,\n",
       " 'usage': 'Casual',\n",
       " 'productDisplayName': 'Turtle Check Men Navy Blue Shirt',\n",
       " 'price': 67,\n",
       " 'product_id': 15970}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get one example\n",
    "PRODUCTS_DATA[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features each product has are:\n",
    "\n",
    "- **Gender:** Target audience for the product, such as \"Men,\" \"Women,\" or \"Unisex.\"\n",
    "- **Master Category:** Broad classification like \"Apparel\" or \"Footwear.\"\n",
    "- **Sub Category:** Specific category within a master category, such as \"Topwear.\"\n",
    "- **Article Type:** Exact type of product, e.g., \"Shirts\" or \"Jackets.\"\n",
    "- **Base Colour:** Main color of the product, important for customer choice.\n",
    "- **Season:** Intended season for the product, e.g., \"Summer\" or \"Winter.\"\n",
    "- **Year:** Year of release or collection.\n",
    "- **Usage:** Intended use or occasion, like \"Casual\" or \"Formal.\"\n",
    "- **Product Display Name:** Descriptive name used in marketing.\n",
    "- **Price:** Cost of the product.\n",
    "- **Product ID:** Unique identifier for managing and tracking inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2-2'></a>\n",
    "### 2.2 FAQ Database\n",
    "\n",
    "Now let's load the FAQ database. And explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FAQ = joblib.load(\"dataset/faq.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are your store hours?',\n",
       "  'answer': 'Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday.',\n",
       "  'type': 'general information'},\n",
       " {'question': 'Where is Fashion Forward Hub located?',\n",
       "  'answer': 'Fashion Forward Hub is primarily an online store. Our corporate office is located at 123 Fashion Lane, Trend City, Style State.',\n",
       "  'type': 'general information'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an example\n",
    "FAQ[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the FAQs are in a list with dictionaries containing `question`, `answer` and `type`. In this assignment you will work with the FAQ as a hardcoded string into a prompt, so you won't need to have a collection for querying on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Task routing\n",
    "---\n",
    "<a id='3-1'></a>\n",
    "### 3.1 Deciding if a query is FAQ or Product related\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will start building the framework for your RAG system. \n",
    "\n",
    "The idea is to create a router to decide if an instruction is about FAQ or about products (this conveys specific information about products and possible creative instructions, like creating a look for a specific occasion).\n",
    "\n",
    "This function will input a query the user makes and output if it is FAQ or Product related.\n",
    "\n",
    "<a id='ex01'></a>\n",
    "### Exercise 1\n",
    "\n",
    "In the function `check_if_faq_or_product`, you need to create a hardcoded `prompt` variable, containing the context to instruct the model to behave properly, i.e., to correctly decide where the query belongs to.\n",
    "\n",
    "**Hints**: \n",
    "- Be specific, instruct the LLM to provide only two classes - FAQ or Product - **They must have these exact names**. \n",
    "- Add examples with the correct label (try adding questions that the LLM might struggle with).\n",
    "- Restrict the max_tokens to 1.\n",
    "- Do not forget to include the query in the prompt! \n",
    "- Set low temperatures to avoid too much randomness.\n",
    "- If the LLM fails to return FAQ or Product, return `None`, so you can handle it later.\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 1</strong></summary>\n",
    "    Start by focusing on how to construct the prompt string. You'll need to include clear instructions and incorporate the provided query into it to ensure the LLM knows what to categorize.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary style=\"color: green;\"><strong>Hint 2</strong></summary>\n",
    "  <p>When creating the <code>prompt</code>, include several examples of questions with their expected labels.</p>\n",
    "  <p>This will help guide the LLM on how to categorize different kinds of queries as either FAQ or Product-related.</p>\n",
    "  <p>You can start with something like <code>Label the following instruction as an FAQ related answer or a product related answer.</code> You might want to add one or two sentences explaining what an FAQ and product queries are. Then, include a few examples with their respective desired label.</p>\n",
    "  <p>E.g., <code>Is there a refund for incorrectly bought clothes? Label: FAQ</code>.</p>\n",
    "  <p>Try writing 4‚Äì5 examples that cover a variety of possibilities. At the end, write the query you want the model to decide. <b>Important: Don't forget to explicitly write that the model should output only one word.</b> Something like: <code>Return only one of the two labels: FAQ or Product.</code></p>\n",
    "  <p>Add the query at the end.</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 3</strong></summary>\n",
    "    After setting up the <code>prompt</code>, generate the parameters required for the LLM call. Use `generate_params_dict` with a low temperature (e.g., 0). Then, call `generate_with_single_input` using these parameters. Finally, check if the label is <code>FAQ</code> or <code>Product</code>.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Prompt Example</strong></summary>\n",
    "    <p>Here there is a simple prompt example where you can start working with. You may add more examples!</p>\n",
    "    <pre><code>\n",
    "Label the following instruction as an FAQ-related query or a product-related query.\n",
    "Product-related answers are specific to product information or require using product details to answer. Products are clothes from a store. \n",
    "An FAQ question addresses common inquiries and provides answers to help users find the information they need.\n",
    "Examples:\n",
    "        Is there a refund for incorrectly bought clothes? Label: FAQ\n",
    "        Tell me about the cheapest T-shirts that you have. Label: Product\n",
    "        Do you have blue T-shirts under 100 dollars? Label: Product\n",
    "        I bought a T-shirt and I didn't like it. How can I get a refund? Label: FAQ\n",
    "\n",
    "Return only one of the two labels: FAQ or Product.\n",
    "Instruction: {query}\n",
    "    </code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CELL \n",
    "\n",
    "def check_if_faq_or_product(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether a given instruction prompt is related to a frequently asked question (FAQ) or a product inquiry.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The instruction or query to be labeled as either FAQ or product-related.\n",
    "\n",
    "    Returns:\n",
    "    - str: The label 'FAQ' if the prompt is classified as a frequently asked question, 'Product' if it relates to product information, or\n",
    "      None if the label is inconclusive.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Set the hardcoded prompt. Remember to include the query, clear instructions (explicitly tell the LLM to return FAQ or Product)\n",
    "    # Include examples of question / desired label pairs.\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Determine the category of the following query as either \"FAQ\" or \"Product\" inquiry related for a retail company called Fashion Forward Hub.\n",
    "  - FAQ queries: These are related to frequently asked questions such as store opening time, closing time,  store locations.\n",
    "  - Product queries: These are related to product information such as colour, price and gender. \n",
    "  \n",
    "  Examples:\n",
    "\n",
    "1. Query: ‚ÄúWhat are your store opening hours?‚Äù Expected answer: FAQ\n",
    "2. Query: ‚ÄúIs there a Fashion Forward hub located in London?‚Äù Expected answer: FAQ\n",
    "3. Query: ‚ÄúWhat is the price of this shirt?‚Äù Expected answer: Product\n",
    "4. Query: ‚ÄúWhat colour are these shirts available in?‚Äù Expected answer: Product\n",
    "5. Query: ‚ÄúIs there a toilet in Fashion Forward Hub store‚Äù Expected answer: FAQ\n",
    "6. Query: ‚ÄúWhat season can I wear this shirt‚Äù Expected answer: Product \n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Instructions: Respond with ‚ÄúFAQ‚Äù if the query pertains to FAQ queries or ‚ÄúProduct‚Äù if it pertains to Product queries.\n",
    "Answer only one single word.\n",
    "\"\"\"\n",
    "\n",
    "    # Get the kwargs dictionary to call the LLM, with PROMPT as prompt, low temperature (0.3 - 0.5)\n",
    "    # The function call is generate_params_dict, pass the PROMPT and the correct temperature\n",
    "    \n",
    "    kwargs =  generate_params_dict(prompt, temperature=0.4, top_p=0.4)\n",
    "\n",
    "    # Call generate_with_single_input with **kwargs\n",
    "    response = generate_with_single_input(**kwargs)\n",
    "    # Get the label by accessing the 'content' key of the response dictionary\n",
    "\n",
    "    label = response['content']\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is your return policy? Label: FAQ\n",
      "Query: Give me three examples of blue T-shirts you have available. Label: Product\n",
      "Query: How can I contact the user support? Label: FAQ\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>504 Gateway Timeout ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront) HTTP3 Server\nRequest ID: tHm1wkoTsotcHl0i-ew9N6sxpSf1UHahsX7SjKfMea72lDikiFfK_Q&#x3D;&#x3D;\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m queries = [\u001b[33m'\u001b[39m\u001b[33mWhat is your return policy?\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      2\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mGive me three examples of blue T-shirts you have available.\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      3\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mHow can I contact the user support?\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      4\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mDo you have blue Dresses?\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mCreate a look suitable for a wedding party happening during dawn.\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     response = \u001b[43mcheck_if_faq_or_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     label = response\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mcheck_if_faq_or_product\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     42\u001b[39m kwargs =  generate_params_dict(prompt, temperature=\u001b[32m0.4\u001b[39m, top_p=\u001b[32m0.4\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Call generate_with_single_input with **kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m response = \u001b[43mgenerate_with_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Get the label by accessing the 'content' key of the response dictionary\u001b[39;00m\n\u001b[32m     48\u001b[39m label = response[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/utils.py:45\u001b[39m, in \u001b[36mgenerate_with_single_input\u001b[39m\u001b[34m(prompt, role, top_p, temperature, max_tokens, model, together_api_key, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m response = requests.post(url, json=payload, verify=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.ok:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while calling LLM: f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     47\u001b[39m     json_dict = json.loads(response.text)\n",
      "\u001b[31mException\u001b[39m: Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>504 Gateway Timeout ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront) HTTP3 Server\nRequest ID: tHm1wkoTsotcHl0i-ew9N6sxpSf1UHahsX7SjKfMea72lDikiFfK_Q&#x3D;&#x3D;\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>"
     ]
    }
   ],
   "source": [
    "queries = ['What is your return policy?', \n",
    "           'Give me three examples of blue T-shirts you have available.', \n",
    "           'How can I contact the user support?', \n",
    "           'Do you have blue Dresses?',\n",
    "           'Create a look suitable for a wedding party happening during dawn.']\n",
    "\n",
    "for query in queries:\n",
    "    response = check_if_faq_or_product(query)\n",
    "    label = response\n",
    "    print(f\"Query: {query} Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Query: What is your return policy? Label: FAQ\n",
    "Query: Give me three examples of blue Tshirts you have available. Label: Product\n",
    "Query: How can I contact the user support? Label: FAQ\n",
    "Query: Do you have blue Dresses? Label: Product\n",
    "Query: Create a look suitable for a wedding party happening during dawn. Label: Product\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "unittests.test_check_if_faq_or_product(check_if_faq_or_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-2'></a>\n",
    "### 3.2 Answering a FAQ question\n",
    "\n",
    "Now that you have a method to decide whether a query is for FAQ or Product, you will create another function to answer a FAQ question.\n",
    "\n",
    "This function also needs a hardcoded prompt and the FAQ question and answer pairs. For that, you will create a FAQ layout with these pairs. \n",
    "\n",
    "First, let's recall how the FAQ JSON is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are your store hours?',\n",
       " 'answer': 'Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday.',\n",
       " 'type': 'general information'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the structure of the first element\n",
    "FAQ[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex04'></a>\n",
    "\n",
    "#### 3.2.1 Creating the FAQ Layout\n",
    "\n",
    "Now you will generate the FAQ layout as discussed above.\n",
    "\n",
    "The FAQ Layout will be the following:\n",
    "\n",
    "```\n",
    "Question: FAQ Question 1, Answer: FAQ Answer 1, Type: FAQ Type 1\n",
    "...\n",
    "Question: FAQ Question 25, Answer: FAQ Answer 25, Type: FAQ Type 25\n",
    "```\n",
    "\n",
    "This function is given to you. Feel free to change the FAQ layout if you want to - but do so after finishing the assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_faq_layout(faq_dict: list) -> str:\n",
    "    \"\"\"\n",
    "    Generates a formatted string layout for a list of FAQs.\n",
    "\n",
    "    This function iterates through a dictionary of frequently asked questions (FAQs) and constructs\n",
    "    a string where each question is followed by its corresponding answer and type.\n",
    "\n",
    "    Parameters:\n",
    "    - faq_dict (list): A list of dictionaries, each containing keys 'question', 'answer', and 'type' \n",
    "      representing an FAQ entry.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string representing the formatted layout of FAQs, with each entry on a separate line.\n",
    "    \"\"\"\n",
    "    # Initialize an empty string\n",
    "    t = \"\"\n",
    "\n",
    "    # Iterate over every FAQ question in the FAQ list\n",
    "    for f in faq_dict:\n",
    "        # Append the question with formatted string (remember to use f-string and access the values as f['question'], f['answer'] and so on)\n",
    "        # Also, do not forget to add a new line character (\\n) at the end of each line.\n",
    "        t += f\"Question: {f['question']} Answer: {f['answer']} Type: {f['type']}\\n\" \n",
    "  \n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are your store hours? Answer: Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday. Type: general information\n",
      "Question: Where is Fashion Forward Hub located? Answer: Fashion Forward Hub is primarily an online store. Our corporate office is located at 123 Fashion Lane, Trend City, Style State. Type: general information\n",
      "Question: Do you have a physical store location? Answer: At this time, we operate exclusively online. This allows us to offer a broader selection and lower prices directly to you. Type: general information\n",
      "Question: How can I create an account with Fashion Forward Hub? Answer: Click on 'Sign Up' in the top right corner of our website and follow the instructions to set up your account. Type: general information\n",
      "Question: How do I subscribe to your newsletter? Answer: To receive the latest updates and promotions, sign up for our newsletter at the bottom of our homepage. Type: general information\n",
      "Question:\n"
     ]
    }
   ],
   "source": [
    "FAQ_LAYOUT = generate_faq_layout(FAQ)\n",
    "print(FAQ_LAYOUT[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='ex02'></a>\n",
    "### Exercise 2\n",
    "---\n",
    "Great! Now that you have the FAQ layout ready, your next task is to create a function that answers questions based on the FAQ content. You‚Äôll inject the FAQ layout into a new, hardcoded prompt. How you do this is up to you‚Äîone common approach is to wrap the FAQ layout using the `<FAQ> </FAQ>` tags.\n",
    "\n",
    "Be sure to write a prompt with clear, explicit instructions. Also, **don‚Äôt forget to include the FAQ layout** you created earlier! You can insert it into your f-string using `{FAQ_LAYOUT}` like this:\n",
    "\n",
    "```python\n",
    "f\"FAQ LAYOUT: {FAQ_LAYOUT}\"\n",
    "```\n",
    "---\n",
    "**How will you be graded?**  \n",
    "The grader will check if your prompt includes the original question and whether your function correctly matches it to the relevant FAQ answers.\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 1</strong></summary>\n",
    "    Think about how to effectively integrate the FAQ content into your prompt. The variable <code>FAQ_LAYOUT</code> already holds the FAQ data, so you can include it directly in your prompt using an f-string. For example, start with something like <code>You will be provided with an FAQ for a clothing store.</code> Then, give the model clear instructions, such as:\n",
    "    <ol>\n",
    "        <li>Use multiple FAQ answers if necessary.</li>\n",
    "        <li>Only answer the question asked.</li>\n",
    "        <li>Base the answer solely on the provided FAQ.</li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 2</strong></summary>\n",
    "    Use a placeholder like <code>{FAQ_LAYOUT}</code> in your prompt to include the FAQ data. This ensures the LLM has the full context to generate accurate answers. A helpful format might be:  \n",
    "    <code>&lt;FAQ&gt;<br>PROVIDED FAQ: {FAQ_LAYOUT}<br>&lt;/FAQ&gt;</code>\n",
    "</details>\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 3</strong></summary>\n",
    "    After constructing your <code>prompt</code>, use <code>generate_params_dict</code> to create the parameters, passing in your prompt and any required keyword arguments. Then, call <code>generate_with_single_input</code> using your prompt to get the model‚Äôs response.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Prompt Example</strong></summary>\n",
    "    <p>Here there is a simple prompt example where you can start working with. </p>\n",
    "    <pre><code>\n",
    "You will be provided with an FAQ for a cloth store. \n",
    "    Answer the instruction based on it. You might use more than one question and answer to make your answer. Only answer the question and do not mention that you have access to a FAQ. \n",
    "    &lt;FAQ&gt;\n",
    "    PROVIDED FAQ: {FAQ_LAYOUT}\n",
    "    &lt;/FAQ&gt;\n",
    "    Question: {query}\n",
    "    </code></pre>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CELL\n",
    "\n",
    "def query_on_faq(query: str, **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Constructs a prompt to query an FAQ system and generates a response.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query about which the function seeks to provide an answer from the FAQ.\n",
    "    - **kwargs: Optional keyword arguments for extra configuration of prompt parameters.\n",
    "\n",
    "    Returns:\n",
    "    - str: The response generated from the LLM based on the input query and FAQ layout.\n",
    "\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Make the prompt. Don't forget to add the FAQ_LAYOUT and the query in it!\n",
    "    prompt = f\"\"\"\n",
    "    Answer the user query using this list of FAQs {FAQ_LAYOUT}.\n",
    "    \n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the parameters dict with PROMPT and **kwargs \n",
    "    kwargs = generate_params_dict(prompt, temperature=0.4, top_p=0.4)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = query_on_faq(\"I got my cloth but I didn't like it. How can I return it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = generate_with_single_input(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can return your item through our Returns Center. To initiate the return process, select the item you wish to return and the desired replacement from the options provided. Our team will guide you through the next steps. Please note that returns are accepted within 30 days of delivery, and conditions apply for specific categories like accessories.\n"
     ]
    }
   ],
   "source": [
    "print(content['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The related FAQ questions about returns are here:\n",
    "\n",
    "```\n",
    "Question: What is your return policy timeframe? Answer: We accept returns within 30 days of delivery. Conditions apply for specific categories like accessories. Type: returns and exchanges\n",
    "\n",
    "Question: Are return shipping costs covered? Answer: We provide a prepaid return label for domestic returns. For international returns, shipping is at the customer's cost. Type: returns and exchanges\n",
    "```\n",
    "\n",
    "Analyze the model's answer and check if it makes sense given these two questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "unittests.test_query_on_faq(query_on_faq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-3'></a>\n",
    "### 3.3 Decide the Nature of a Product-Related Question\n",
    "\n",
    "Now, let's start working with product-related queries.\n",
    "\n",
    "<a id='ex03'></a>\n",
    "### Exercise 3\n",
    "---\n",
    "Your employer only wants the chatbot to answer the following types of queries:\n",
    "\n",
    "- **Technical queries** ‚Äì asking for descriptions of specific products, such as whether a blue dress is available or requesting three examples of red T-shirts suitable for sunny days.\n",
    "- **Creative queries** ‚Äì asking for help creating a stylish look for visiting a museum.\n",
    "\n",
    "You will proceed as before. Create a prompt with clear instructions (and examples!) alongside the query. Remember to ensure the model only outputs **\"creative\"** or **\"technical\"** by:\n",
    "\n",
    "- setting a low temperature,\n",
    "- and explicitly stating this in the prompt.\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 1</strong></summary>\n",
    "    Consider how to frame a prompt that clearly instructs the LLM to classify the nature of a query. This will involve using examples within the <code>prompt</code>. Include strong examples‚Äîespecially cases where the LLM might struggle to decide‚Äîand label them appropriately. This exercise is very similar to Exercise 1. You might start with something like:  \n",
    "    <code>Decide if the following query is a query that requires creativity (creating, composing, making new things) or technical (information about products, prices, etc.). Label it as creative or technical.</code>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 2</strong></summary>\n",
    "    Use example queries to show the model how different types of queries are labeled. Include queries that are clearly creative or technical within the <code>prompt</code> for clarity. For instance:<br>\n",
    "    <pre><code>\n",
    "Examples:\n",
    "Give me suggestions on a nice look for a nightclub. Label: creative\n",
    "What are the blue dresses you have available? Label: technical\n",
    "</code></pre>\n",
    "    Finish by adding the query to be analyzed. Something like:  \n",
    "    <code>Query to be analyzed: {query}. Only output one token with the label.</code>  \n",
    "    should be enough.  \n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 3</strong></summary>\n",
    "    After creating the <code>PROMPT</code>, use <code>generate_params_dict</code> to prepare the parameters. Set <code>temperature</code> to 0 for predictability and <code>max_tokens</code> to 1 to ensure a concise label. Then, call <code>generate_with_single_input</code> to get the label and extract it using <code>response['content']</code>.\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Prompt Example</strong></summary>\n",
    "    <p>Here there is a simple prompt example where you can start working with. You may add more examples!</p>\n",
    "    <pre><code>\n",
    "Decide if the following query is a query that requires creativity (creating, composing, making new things) or technical (information about products, prices, etc.). Label it as creative or technical.\n",
    "              Examples:\n",
    "              Give me suggestions on a nice look for a nightclub. Label: creative\n",
    "              What are the blue dresses you have available? Label: technical\n",
    "              Give me three T-shirts for summer. Label: technical\n",
    "              Give me a look for attending a wedding party. Label: creative\n",
    "              Query to be analyzed: {query}. Only output one token: the label.\n",
    "    </code></pre>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CELL\n",
    "\n",
    "def decide_task_nature(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether a query is creative or technical.\n",
    "\n",
    "    This function constructs a prompt for an LLM to decide if a given query requires a creative response,\n",
    "    such as making suggestions or composing ideas, or a technical response, such as providing product details or prices.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query to be evaluated for its nature.\n",
    "\n",
    "    Returns:\n",
    "    - str: The label 'creative' if the query requires creative input, or 'technical' if it requires technical information.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create the prompt. Remember to include the query, examples, and clear instructions (not necessarily in this order!)\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "    Determine the category of the following query as either \"creative\" or \"technical\" inquiry related for a retail company called Fashion Forward Hub.\n",
    "  - creative queries: These are related to creative things such as asking what clothes should be worn in summer.\n",
    "  - technical queries: These are related to product specific information such as colour, availability, price and gender. \n",
    "  \n",
    "  Examples:\n",
    "\n",
    "1. Query: ‚ÄúIs the blue shirt available in store?‚Äù Expected answer: technical\n",
    "2. Query: ‚ÄúDo you have winter jacketa available online‚Äù Expected answer: technical\n",
    "3. Query: ‚ÄúGive me two sneakers in vibrant colours‚Äù Expected answer: technical\n",
    "4. Query: ‚ÄúWhat colour Jeans should I wear in summer?‚Äù Expected answer: creative\n",
    "5. Query: ‚ÄúGive me ideas for summer dresses for a young girl‚Äù Expected answer: FAQ\n",
    "6. Query: ‚ÄúWhat colour top can I wear with my dark blue jeans?‚Äù Expected answer: Product \n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Instructions: Respond with ‚Äúcreative‚Äù if the query pertains to creative queries or ‚Äútechnical‚Äù if it pertains to Product specific questions.\n",
    "Answer only one single word.\n",
    "\"\"\"\n",
    "\n",
    "    # Generate the kwargs dictionary by passing the PROMPT, setting temperature to 0 and max_tokens to 1\n",
    "    kwargs =  generate_params_dict(prompt, temperature=0.4, top_p=0.4)\n",
    "\n",
    "    # Call generate_with_single_input with **kwargs\n",
    "    response = generate_with_single_input(**kwargs)\n",
    "\n",
    "    # Get the label\n",
    "    label = response['content']\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = [\"Give me two sneakers with vibrant colors.\",\n",
    "           \"What are the most expensive clothes you have in your catalogue?\",\n",
    "           \"I have a green dress and I like a suggestion on an accessory to match with it.\",\n",
    "           \"Give me three trousers with vibrant colors you have in your catalogue.\",\n",
    "           \"Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather.\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me two sneakers with vibrant colors. Label: creative\n",
      "Query: What are the most expensive clothes you have in your catalogue? Label: technical\n",
      "Query: I have a green dress and I like a suggestion on an accessory to match with it. Label: creative\n",
      "Query: Give me three trousers with vibrant colors you have in your catalogue. Label: technical\n",
      "Query: Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather. Label: creative\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    label = decide_task_nature(query)\n",
    "    print(f\"Query: {query} Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Query: Give me two sneakers with vibrant colors. Label: technical\n",
    "Query: What are the most expensive clothes you have in your catalogue? Label: technical\n",
    "Query: I have a green Dress and I like a suggestion on an acessory to match with it. Label: creative\n",
    "Query: Give me three trousers with vibrant colors you have in your catalogue. Label: technical\n",
    "Query: Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather. Label: creative\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "unittests.test_decide_task_nature(decide_task_nature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-4'></a>\n",
    "### 3.4 Retrieving the Parameters for a Given Task\n",
    "\n",
    "<a id='ex04'></a>\n",
    "### Exercise 4\n",
    "---\n",
    "In this exercise, you will create a function that, given a task, returns the appropriate values for `top_p` and `temperature`.\n",
    "\n",
    "For **technical** queries, **low randomness is preferred**, whereas for **creative** tasks, **higher randomness might be more suitable**. \n",
    "\n",
    "**Important:** If the task is neither `technical` nor `creative` (for example, if the LLM fails to output a valid label), then fallback to a default set of parameters. You can decide whether to choose a middle ground between low and high randomness or stick to low randomness as a conservative approach.\n",
    "\n",
    "**Note**: Remember that a temperature that is too high will lead the model to nonsense results so keep it below **1.3** and if it is close to **1.3**, be sure to lower the **top_p**. Also, remember that *top_p* cannot be greater than 1!\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 1</strong></summary>\n",
    "    Begin by considering how to map each task type to its corresponding parameters. Think about how creative and technical tasks might require different model settings. Remember that if the temperature is too big, you might get nonsense results if you don't control the top_p parameter! Suggestions for temperature are: 1 for creative and 0.3 for technical. Adjust top_p accordingly.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 2</strong></summary>\n",
    "    Use a dictionary (<code>PARAMETERS_DICT</code>) to store the parameter configurations for the 'creative' and 'technical' tasks. This will make retrieving parameters straightforward based on the task label.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 3</strong></summary>\n",
    "    Implement logic to retrieve parameters: Check if <code>task</code> matches 'technical' or 'creative', and assign the corresponding parameter set from <code>PARAMETERS_DICT</code>. Use a default parameter set if <code>task</code> doesn't match expected values to ensure graceful handling of unexpected input.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CELL \n",
    "\n",
    "def get_params_for_task(task: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves specific LLM parameters based on the nature of the task.\n",
    "\n",
    "    This function returns parameter sets optimized for either creative or technical tasks.\n",
    "    Creative tasks benefit from higher randomness, while technical tasks require more focus and precision.\n",
    "    A default parameter set is returned for unrecognized task types.\n",
    "\n",
    "    Parameters:\n",
    "    - task (str): The nature of the task ('creative' or 'technical').\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing 'top_p' and 'temperature' settings appropriate for the task.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # Define the parameter sets for technical and creative tasks\n",
    "    PARAMETERS_DICT = {\n",
    "        \"creative\": {\"top_p\": None, 'temperature': None},\n",
    "        \"technical\": {'top_p': None, 'temperature': None}\n",
    "    }\n",
    "    \n",
    "    # Return the corresponding parameter set based on task type\n",
    "    if task == 'technical':\n",
    "        param_dict = {\"top_p\": 0.4, \"temperature\": 0.4}\n",
    "    elif task == 'creative':\n",
    "        param_dict = {\"top_p\": 0.8, \"temperature\": 1.5}\n",
    "    else:\n",
    "        # Fallback to a default parameter set for unrecognized task types\n",
    "        param_dict = {\"top_p\": 0.5, \"temperature\": 1.0}\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return param_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_p': 0.4, 'temperature': 0.4}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_params_for_task(\"technical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output (results may vary depending on the values you chose for top_p and temperature)**\n",
    "```\n",
    "{'top_p': 0.7, 'temperature': 0.3}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "unittests.test_get_params_for_task(get_params_for_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4 - Retrieving Items Based on Metadata Inferred from a Query\n",
    "---\n",
    "In this section, you‚Äôll create a function to extract useful metadata to help filter the items shown to it. You‚Äôll get a JSON file with different features and all the possible values found in the dataset. Your job is to pass these values to your database, so the LLM can pick the ones that make the most sense. And of course, you'll also need to handle situations where the LLM might not find a correct value.\n",
    "\n",
    "The values you‚Äôll focus on are:\n",
    "- gender  \n",
    "- masterCategory  \n",
    "- articleType  \n",
    "- baseColour  \n",
    "- season  \n",
    "- usage\n",
    "\n",
    "These were chosen because they strike a good balance ‚Äî they‚Äôre specific enough to be useful, but general enough to avoid empty results. Some other features in the dataset are too detailed and could lead to no matches. Also, including every single value would make the prompt too large, which could slow things down and raise costs ‚Äî something to keep in mind when building real-world solutions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'Men',\n",
       " 'masterCategory': 'Apparel',\n",
       " 'subCategory': 'Topwear',\n",
       " 'articleType': 'Shirts',\n",
       " 'baseColour': 'Navy Blue',\n",
       " 'season': 'Fall',\n",
       " 'year': 2011.0,\n",
       " 'usage': 'Casual',\n",
       " 'productDisplayName': 'Turtle Check Men Navy Blue Shirt',\n",
       " 'price': 67,\n",
       " 'product_id': 15970}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remember the data structure of a product\n",
    "PRODUCTS_DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to generate the dictionary with the possible values for each key\n",
    "values = {}\n",
    "for d in PRODUCTS_DATA:\n",
    "    for key, val in d.items():\n",
    "        if key in ('product_id', 'price', 'productDisplayName', 'subCategory', 'year'):\n",
    "            continue\n",
    "        if key not in values.keys():\n",
    "            values[key] = set()\n",
    "        values[key].add(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All seasons', 'Fall', 'Spring', 'Summer', 'Winter'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of possible values for the feature 'season'\n",
    "values['season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5-1'></a>\n",
    "\n",
    "<a id='4-1'></a>\n",
    "### 4.1 Generate metadata\n",
    "\n",
    "<a id='ex08'></a>\n",
    "\n",
    "<a id='ex05'></a>\n",
    "### Exercise 5\n",
    "---\n",
    "The next function‚Äôs purpose is to extract potential metadata from a given query. The approach is to construct a prompt that incorporates the `values` dictionary, which lists possible feature values. the LLM is then asked to generate a JSON response suggesting metadata relevant to the query. You have the flexibility to add more information as needed.\n",
    "\n",
    "In addition to the metadata features, the LLM must also handle price constraints. If the query specifies a price range, the JSON should include a key like this:\n",
    "\n",
    "```json\n",
    "\"price\": {\"min\": min_value, \"max\": max_value}\n",
    "```\n",
    "\n",
    "If no price constraint is provided, the LLM should default to:\n",
    "\n",
    "```json\n",
    "\"price\": {\"min\": 0, \"max\": \"inf\"}\n",
    "```\n",
    "\n",
    "Here is an example of the expected JSON format you should explicitly include in your prompt to help guide the LLM:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"gender\": [\"Women\"],\n",
    "    \"masterCategory\": [\"Apparel\"],\n",
    "    \"articleType\": [\"Dresses\"],\n",
    "    \"baseColour\": [\"Blue\"],\n",
    "    \"price\": {\"min\": 0, \"max\": \"inf\"},\n",
    "    \"usage\": [\"Formal\"],\n",
    "    \"season\": [\"All seasons\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Important Note**: When using f-strings in Python, you must use double curly braces within the string to ensure it is parsed as a literal. For example:\n",
    "\n",
    "```python\n",
    "f\"\"\"Any text here {{\n",
    "    \"gender\": [\"Women\"],\n",
    "    \"masterCategory\": [\"Apparel\"],\n",
    "    \"articleType\": [\"Dresses\"],\n",
    "    \"baseColour\": [\"Blue\"],\n",
    "    \"price\": {{\"min\": 0, \"max\": \"inf\"}},\n",
    "    \"usage\": [\"Formal\"],\n",
    "    \"season\": [\"All seasons\"]\n",
    "}}\"\"\"\n",
    "```\n",
    "\n",
    "**Note**: To avoid truncating a JSON, set the `max_tokens` value for something around `1500`!\n",
    "\n",
    "Always remember to use double curly braces within an f-string to ensure that Python interprets them correctly as part of the string.\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 1</strong></summary>\n",
    "    When constructing the prompt, focus on explicitly instructing the LLM to output a JSON format that includes specific metadata keys. Ensure that the prompt clearly includes the user's query and describes what the model should focus on extracting from it. You can start with something like:\n",
    "    <pre>\n",
    "    <code>\n",
    "    One query will be provided. For the given query, there will be a call on vector database to query relevant clothing items. \n",
    "    Generate a JSON with useful metadata to filter the products in the query. Possible values for each feature is in the following JSON: {values}\n",
    "    </code>\n",
    "    </pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 2</strong></summary>\n",
    "    Incorporate the `values` within your prompt to inform the LLM of the potential values for each feature. Explain to the LLM the purpose of generating metadata and be explicit about including keys like gender, masterCategory, articleType, baseColour, price, usage, and season. Your prompt should contain a text like this:\n",
    "    <pre>\n",
    "    <code>\n",
    "    Provide a JSON with the features that best fit in the query (can be more than one, write in a list). Also, if present, add a price key, saying if there is a price range (between values, greater than or smaller than some value).\n",
    "    Only return the JSON, nothing more. price key must be a JSON with \"min\" and \"max\" values (0 if no lower bound and inf if no upper bound). \n",
    "    Always include gender, masterCategory, articleType, baseColour, price, usage and season as keys. All values must be within lists.\n",
    "    If there is no price set, add min = 0 and max = inf.\n",
    "    Only include values that are given in the JSON above. \n",
    "    </code>\n",
    "    </pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Hint 3</strong></summary>\n",
    "    In your prompt, make it clear that the `price` key in the output JSON must be structured as a dictionary with \"min\" and \"max\" values. Include instructions for handling cases with unspecified price constraints, defaulting to {\"min\": 0, \"max\": \"inf\"}. Reinforce that each feature's value should be within a list form, and provide an example JSON to demonstrate the desired format clearly. An expected JSON structure might be something like:\n",
    "    <pre>\n",
    "    <code>\n",
    "    Example of expected JSON:\n",
    "    {{\n",
    "    \"gender\": [\"Women\"],\n",
    "    \"masterCategory\": [\"Apparel\"],\n",
    "    \"articleType\": [\"Dresses\"],\n",
    "    \"baseColour\": [\"Blue\"],\n",
    "    \"price\": {{\"min\": 0, \"max\": \"inf\"}},\n",
    "    \"usage\": [\"Formal\"],\n",
    "    \"season\": [\"All seasons\"]\n",
    "    }}\n",
    "    </code>\n",
    "    </pre>\n",
    "\n",
    "Don't forget to add the user query at the end!\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary style=\"color: green;\"><strong>Prompt Example</strong></summary>\n",
    "    <p>Here there is a simple prompt example where you can start working with. You may add more examples!</p>\n",
    "    <pre>\n",
    "    <code>\n",
    "    A query will be provided. Based on this query, a vector database will be searched to find relevant clothing items.\n",
    "    Generate a JSON object containing useful metadata to filter products for this query.\n",
    "    The possible values for each feature are given in the following JSON: {values}\n",
    "\n",
    "    Provide a JSON containing the features that best match the query (values should be in lists, multiple values possible).\n",
    "    If a price range is mentioned, include a price key specifying the range (between values, greater than, or less than).\n",
    "    Return only the JSON, nothing else. The price key must be a JSON object with \"min\" and \"max\" values (use 0 if no lower bound, and \"inf\" if no upper bound).\n",
    "    Always include the following keys: gender, masterCategory, articleType, baseColour, price, usage, and season.\n",
    "    If no price is specified, set min = 0 and max = inf.\n",
    "    Include only values present in the JSON above.\n",
    "\n",
    "    Example of expected JSON:\n",
    "\n",
    "    {{\n",
    "      \"gender\": [\"Women\"],\n",
    "      \"masterCategory\": [\"Apparel\"],\n",
    "      \"articleType\": [\"Dresses\"],\n",
    "      \"baseColour\": [\"Blue\"],\n",
    "      \"price\": {{\"min\": 0, \"max\": \"inf\"}},\n",
    "      \"usage\": [\"Formal\"],\n",
    "      \"season\": [\"All seasons\"]\n",
    "    }}\n",
    "\n",
    "    Query: {query}\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CELL\n",
    "\n",
    "def generate_metadata_from_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates metadata in JSON format based on a given query to filter clothing items.\n",
    "\n",
    "    This function constructs a prompt for an LLM to produce a JSON object\n",
    "    that will guide filtering in a vector database query for clothing items.\n",
    "    It uses possible values from a predefined set and ensures that only relevant metadata\n",
    "    is included in the output JSON.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): A description of specific clothing-related needs.\n",
    "\n",
    "    Returns:\n",
    "    - str: A JSON string representing metadata with keys such as gender, masterCategory,\n",
    "      articleType, baseColour, price, usage, and season. Each value in the JSON is a list.\n",
    "      The price is specified as a dictionary with \"min\" and \"max\" keys.\n",
    "      For unrestricted categories, use [\"Any\"], and if no price is specified,\n",
    "      default to {\"min\": 0, \"max\": \"inf\"}.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "\n",
    "    # Construct the prompt.\n",
    "    # Include the query, the desired JSON format, and the possible values (pass {values} where needed).\n",
    "    # Clearly instruct the LLM to include gender, masterCategory, articleType, baseColour, price, usage, and season as keys.\n",
    "    # Specify that the price key must be a JSON object with \"min\" and \"max\" values (0 if no lower bound, \"inf\" if no upper bound).\n",
    "    # If no price is set, default to min = None\n",
    "    \n",
    "    prompt =  f\"\"\"\n",
    "    One query will be provided. For the given query, there will be a call on vector database to query relevant clothing items. \n",
    "    Generate a JSON with useful metadata to filter the products in the query. Return only the JSON, nothing else. The price key must be a JSON object with \"min\" and \"max\" values (use 0 if no lower bound, and \"inf\" if no upper bound).\n",
    "    Always include the following keys: gender, masterCategory, articleType, baseColour, price, usage, and season.\n",
    "    If no price is specified, set min = 0 and max = inf.\n",
    "    \n",
    "    Include only values present in the JSON above. Possible values for each feature is in the following JSON:\n",
    "    \n",
    "    {{\n",
    "    \"gender\": [\"Women\"],\n",
    "    \"masterCategory\": [\"Apparel\"],\n",
    "    \"articleType\": [\"Dresses\"],\n",
    "    \"baseColour\": [\"Blue\"],\n",
    "    \"price\": {{\"min\": 0, \"max\": \"inf\"}},\n",
    "    \"usage\": [\"Formal\"],\n",
    "    \"season\": [\"All seasons\"]\n",
    "    }}\n",
    "    \n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the response with generate_with_single_input using PROMPT, temperature=0 (low randomness), and max_tokens=1500\n",
    "    kwargs =  generate_params_dict(prompt, temperature=0.0, top_p=0.4, max_tokens=1500)\n",
    "    response = generate_with_single_input(**kwargs)\n",
    "    \n",
    "\n",
    "    # Extract the content from the response\n",
    "    content = response['content']\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gender\": \"Men\",\n",
      "    \"masterCategory\": \"Apparel\",\n",
      "    \"articleType\": [\"Shirts\", \"Pants\"],\n",
      "    \"baseColour\": [\"Light\", \"Pastel\"],\n",
      "    \"price\": {\"min\": 0, \"max\": 300},\n",
      "    \"usage\": [\"Casual\"],\n",
      "    \"season\": [\"Summer\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(generate_metadata_from_query(\"Create a look for a man that suits a sunny day in the park. I don't want to spend more than 300 dollars on each piece.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output (result may vary)**\n",
    "```\n",
    "{\n",
    "    \"gender\": [\"Men\"],\n",
    "    \"masterCategory\": [\"Apparel\"],\n",
    "    \"articleType\": [\"Tshirts\", \"Shorts\", \"Sweatshirts\"],\n",
    "    \"baseColour\": [\"Yellow\", \"Orange\", \"White\"],\n",
    "    \"price\": {\"min\": 0, \"max\": 300},\n",
    "    \"usage\": [\"Casual\"],\n",
    "    \"season\": [\"Summer\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "unittests.test_generate_metadata_from_query(generate_metadata_from_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functions are helper functions to extract the JSON from the query. You also need to handle the case where the LLM doesn't provide a valid and recoverable JSON. In this case, the code will just create an empty filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_json_output(llm_output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a string output from an LLM into a JSON object.\n",
    "\n",
    "    This function attempts to clean and parse a JSON-formatted string produced by an LLM.\n",
    "    The input string might contain minor formatting issues, such as unnecessary newlines or single quotes\n",
    "    instead of double quotes. The function attempts to correct such issues before parsing.\n",
    "\n",
    "    Parameters:\n",
    "    - llm_output (str): The string output from the LLM that is expected to be in JSON format.\n",
    "\n",
    "    Returns:\n",
    "    - dict or None: A dictionary if parsing is successful, or None if the input string cannot be parsed into valid JSON.\n",
    "\n",
    "    Exception Handling:\n",
    "    - In case of a JSONDecodeError during parsing, an error message is printed, and the function returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Since the input might be improperly formatted, ensure any single quotes are removed\n",
    "        llm_output = llm_output.replace(\"\\n\", '').replace(\"'\",'').replace(\"}}\", \"}\").replace(\"{{\", \"{\")  # Remove any erroneous structures\n",
    "        \n",
    "        # Attempt to parse JSON directly provided it is a properly-structured JSON string\n",
    "        parsed_json = json.loads(llm_output)\n",
    "        return parsed_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_string = generate_metadata_from_query(\"Give me three blue dresses suitable for a wedding party, less than 200 dollars and at least 50 dollars\")\n",
    "json_output = parse_json_output(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': ['Women'],\n",
       " 'masterCategory': ['Apparel'],\n",
       " 'articleType': ['Dresses'],\n",
       " 'baseColour': ['Blue'],\n",
       " 'price': {'min': 50, 'max': 200},\n",
       " 'usage': ['Formal'],\n",
       " 'season': ['All seasons']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP**: Try with different queries and check if the JSON is properly parsed. If not, investigate why and maybe improve the PROMPT to avoid such issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-2'></a>\n",
    "### 4.2 Loading the Weaviate Product Collection\n",
    "\n",
    "Now it is time to work with the Weaviate collection. It is already given to you and it is the product_data you saw before, but added as a Weaviate collection, so we can query with semantic search and metadata filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "products_collection = client.collections.get('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44423"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-3'></a>\n",
    "### 4.3 Filtering by metadata (NOT GRADED)\n",
    "\n",
    "This next function will create the filters given the metadata. It will create a `Filter` object for each key in the dictionary of metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filter_by_metadata(json_output: dict | None = None):\n",
    "    \"\"\"\n",
    "    Generate a list of Weaviate filters based on a provided metadata dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - json_output (dict) or None: Dictionary containing metadata keys and their values.\n",
    "\n",
    "    Returns:\n",
    "    - list[Filter] or None: A list of Weaviate filters, or None if input is None.\n",
    "    \"\"\"\n",
    "    # If the input dictionary is None, return None immediately\n",
    "    if json_output is None:\n",
    "        return None\n",
    "\n",
    "    # Define a tuple of valid keys that are allowed for filtering\n",
    "    valid_keys = (\n",
    "        'gender',\n",
    "        'masterCategory',\n",
    "        'articleType',\n",
    "        'baseColour',\n",
    "        'price',\n",
    "        'usage',\n",
    "        'season',\n",
    "    )\n",
    "\n",
    "    # Initialize an empty list to store the filters\n",
    "    filters = []\n",
    "\n",
    "    # Iterate over each key-value pair in the input dictionary\n",
    "    for key, value in json_output.items():\n",
    "        # Skip the key if it is not in the list of valid keys\n",
    "        if key not in valid_keys:\n",
    "            continue\n",
    "\n",
    "        # Special handling for the 'price' key\n",
    "        if key == 'price':\n",
    "            # Ensure the value associated with 'price' is a dictionary\n",
    "            if not isinstance(value, dict):\n",
    "                continue\n",
    "\n",
    "            # Extract the minimum and maximum prices from the dictionary\n",
    "            min_price = value.get('min')\n",
    "            max_price = value.get('max')\n",
    "\n",
    "            # Skip if either min_price or max_price is not provided\n",
    "            if min_price is None or max_price is None:\n",
    "                continue\n",
    "\n",
    "            # Skip if min_price is non-positive or max_price is infinity\n",
    "            if min_price <= 0 or max_price == 'inf':\n",
    "                continue\n",
    "\n",
    "            # Add filters for price greater than min_price and less than max_price\n",
    "            filters.append(Filter.by_property(key).greater_than(min_price))\n",
    "            filters.append(Filter.by_property(key).less_than(max_price))\n",
    "        else:\n",
    "            # For other valid keys, add a filter that checks for any of the provided values\n",
    "            filters.append(Filter.by_property(key).contains_any(value))\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is wrapper function, that, given a query, return the desired filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_filters_from_query(query: str) -> list:\n",
    "    json_string = generate_metadata_from_query(query)\n",
    "    json_output = parse_json_output(json_string)\n",
    "    filters = get_filter_by_metadata(json_output)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filters = generate_filters_from_query(\"Give me three T-shirts to use in sunny days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_FilterValue(value=['Men', 'Women'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='gender'),\n",
       " _FilterValue(value=['Apparel'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='masterCategory'),\n",
       " _FilterValue(value=['T-shirts'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='articleType'),\n",
       " _FilterValue(value=['White', 'Light Blue', 'Yellow'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='baseColour'),\n",
       " _FilterValue(value=['Casual', 'Sunny days'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='usage'),\n",
       " _FilterValue(value=['Summer'], operator=<_Operator.CONTAINS_ANY: 'ContainsAny'>, target='season')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\\Note that the filters are there with the correct metadata.\n",
    "\n",
    "The next function will get the relevant products from the query, by generating the filters, running a semantic search using the query, and then perform the metadata filtering to narrow down the possibilities and increase accuracy. \n",
    "\n",
    "It deals with the case where the set of metadata returns too few results by incrementally removing some filters until it gets a result with more than 5 possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_relevant_products_from_query(query: str):\n",
    "    \"\"\"\n",
    "    Retrieve products that are most relevant to a given query by applying filters.\n",
    "\n",
    "    This function generates filters based on the provided query and uses them to find \n",
    "    products that closely match the query criteria. If no filters are applicable or if \n",
    "    the initial search returns a small number of products, the function dynamically reduces \n",
    "    the filtering constraints based on a predefined order of filter importance.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query string used to search for relevant products.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of product objects that are most relevant to the query. If filters are not effective,\n",
    "          it adjusts them to ensure a minimum return of products.\n",
    "    \"\"\"\n",
    "    filters = generate_filters_from_query(query)  # Generate filters based on query\n",
    "\n",
    "    # Check if there are no applicable filters\n",
    "    if filters is None or len(filters) == 0:\n",
    "        # Query the collection without filters, using the query text for relevance\n",
    "        res = products_collection.query.near_text(query, limit=20).objects\n",
    "        return res\n",
    "\n",
    "    # Query with filters and limit to top 20 relevant objects\n",
    "    res = products_collection.query.near_text(query, filters=Filter.all_of(filters), limit=20).objects\n",
    "\n",
    "    # If the result set is fewer than 10 products, try reducing filters to broaden the search\n",
    "    importance_order = ['baseColour', 'masterCategory', 'usage', 'masterCategory', 'season', 'gender']\n",
    "\n",
    "    if len(res) < 10:\n",
    "        # Iterate through the importance order of filters\n",
    "        for i in range(len(importance_order)):\n",
    "            # Create a list of filters that excludes less important ones\n",
    "            filtered_filters = [x for x in filters if x.target not in importance_order[i+1:]]\n",
    "            \n",
    "            # Re-query with the reduced set of filters\n",
    "            res = products_collection.query.near_text(query, filters=Filter.all_of(filtered_filters), limit=20).objects\n",
    "            \n",
    "            # If sufficient products have been found, return early\n",
    "            if len(res) >= 5:\n",
    "                return res\n",
    "\n",
    "    return res  # Return the final set of relevant products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Give me three T-shirts to use in sunny days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = get_relevant_products_from_query(\"Give me three T-shirts to use in sunny days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m t = \u001b[43mget_relevant_products_from_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGive me three blue colour tshirts for men between ¬£100 and ¬£300\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mget_relevant_products_from_query\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_relevant_products_from_query\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Retrieve products that are most relevant to a given query by applying filters.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m          it adjusts them to ensure a minimum return of products.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     filters = \u001b[43mgenerate_filters_from_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate filters based on query\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Check if there are no applicable filters\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filters) == \u001b[32m0\u001b[39m:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Query the collection without filters, using the query text for relevance\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_filters_from_query\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      2\u001b[39m json_string = generate_metadata_from_query(query)\n\u001b[32m      3\u001b[39m json_output = parse_json_output(json_string)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m filters = \u001b[43mget_filter_by_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filters\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mget_filter_by_metadata\u001b[39m\u001b[34m(json_output)\u001b[39m\n\u001b[32m     55\u001b[39m         filters.append(Filter.by_property(key).less_than(max_price))\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m         \u001b[38;5;66;03m# For other valid keys, add a filter that checks for any of the provided values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         filters.append(\u001b[43mFilter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mby_property\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontains_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filters\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/weaviate/collections/classes/filters.py:170\u001b[39m, in \u001b[36m_FilterByProperty.contains_any\u001b[39m\u001b[34m(self, val)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontains_any\u001b[39m(\u001b[38;5;28mself\u001b[39m, val: FilterValuesList) -> _Filters:\n\u001b[32m    169\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Filter on whether the property contains any of the given values.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m == \u001b[32m0\u001b[39m:\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m WeaviateInvalidInputError(\u001b[33m\"\u001b[39m\u001b[33mFilter contains_any must have at least one value\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _FilterValue(\n\u001b[32m    173\u001b[39m         target=\u001b[38;5;28mself\u001b[39m._target_path(),\n\u001b[32m    174\u001b[39m         value=val,\n\u001b[32m    175\u001b[39m         operator=_Operator.CONTAINS_ANY,\n\u001b[32m    176\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "t = get_relevant_products_from_query(\"Give me three blue colour tshirts for men between ¬£100 and ¬£300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.properties\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "t[0].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one of the relevant results is indeed a Tshirt! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-4'></a>\n",
    "### 4.4 Generating the retrieve items as a context (NOT GRADED)\n",
    "\n",
    "Now, for the given retrieved items, let's generate a simple context in the format \n",
    "\n",
    "```\n",
    "Product name: Inkfruit Mens Little Bit More T-shirt. Product Category: Apparel. Product usage: Casual. Product gender: Men. Product Type: Tshirts. Product Category: Topwear Product Color: Yellow. Product Season: Summer. Product Year: 2011.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_items_context(results: list) -> str:\n",
    "    \"\"\"\n",
    "    Compile detailed product information from a list of result objects into a formatted string.\n",
    "\n",
    "    This function takes a list of results, each containing various product attributes, and constructs \n",
    "    a human-readable summary for each product. Each product's details, including ID, name, category, \n",
    "    usage, gender, type, and other characteristics, are concatenated into a string that describes \n",
    "    all products in the list.\n",
    "\n",
    "    Parameters:\n",
    "    results (list): A list of result objects, each having a `properties` attribute that is a dictionary \n",
    "                    containing product attributes such as 'product_id', 'productDisplayName', \n",
    "                    'masterCategory', 'usage', 'gender', 'articleType', 'subCategory', \n",
    "                    'baseColour', 'season', and 'year'.\n",
    "\n",
    "    Returns:\n",
    "    str: A multi-line string where each line contains the formatted details of a single product.\n",
    "         Each product detail includes the product ID, name, category, usage, gender, type, color, \n",
    "         season, and year.\n",
    "    \"\"\"\n",
    "    t = \"\"  # Initialize an empty string to accumulate product information\n",
    "\n",
    "    for item in results:  # Iterate through each item in the results list\n",
    "        item = item.properties  # Access the properties dictionary of the current item\n",
    "\n",
    "        # Append formatted product details to the output string\n",
    "        t += (\n",
    "            f\"Product ID: {item['product_id']}. \"\n",
    "            f\"Product name: {item['productDisplayName']}. \"\n",
    "            f\"Product Category: {item['masterCategory']}. \"\n",
    "            f\"Product usage: {item['usage']}. \"\n",
    "            f\"Product gender: {item['gender']}. \"\n",
    "            f\"Product Type: {item['articleType']}. \"\n",
    "            f\"Product Category: {item['subCategory']} \"\n",
    "            f\"Product Color: {item['baseColour']}. \"\n",
    "            f\"Product Season: {item['season']}. \"\n",
    "            f\"Product Year: {item['year']}.\\n\"\n",
    "        )\n",
    "\n",
    "    return t  # Return the complete formatted string with product details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(generate_items_context(t)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-5'></a>\n",
    "### 4.5 Query on Products (NOT GRADED)\n",
    "\n",
    "You‚Äôre almost there! This section explains the function that queries products based on a given task. The process follows these steps:\n",
    "\n",
    "1. **Query**: Start with a product query.\n",
    "2. **Determine Query Nature**: Identify if the query is technical or creative.\n",
    "3. **Retrieve Relevant Products**: Find products that best match the query criteria.\n",
    "4. **Generate Context**: Build a descriptive context string based on the products.\n",
    "5. **Create Prompt**: Formulate the prompt using the context and the query nature.\n",
    "6. **Generate Parameters**: Prepare parameters suited to the query nature for the LLM.\n",
    "7. **Run Inference**: Perform the inference using the prepared parameters.\n",
    "\n",
    "Let's check the code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_on_products(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Execute a product query process to generate a response based on the nature of the query.\n",
    "\n",
    "    This function analyzes the type of query ‚Äî whether it is technical or creative ‚Äî and retrieves \n",
    "    relevant product information accordingly. It constructs a prompt that includes product details \n",
    "    and the original query, and then generates parameters for querying an LLM.\n",
    "    Finally, it generates a response based on the prompt and returns the content of the response.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The input query string that needs to be analyzed and answered using product data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of keyword arguments (`kwargs`) containing the prompt and additional settings \n",
    "          for creating a response, suitable for input to an LLM or other processing system.\n",
    "\n",
    "    Outputs:\n",
    "    dict: A dictionary with the parameters to call an LLM\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Determine if the query is technical or creative in nature\n",
    "    query_label = decide_task_nature(query) \n",
    "    \n",
    "    # Obtain necessary parameters based on the query type\n",
    "    parameters_dict = get_params_for_task(query_label) \n",
    "    \n",
    "    # Retrieve products that are relevant to the query\n",
    "    relevant_products = get_relevant_products_from_query(query) \n",
    "     \n",
    "    # Create a context string from the relevant products\n",
    "    context = generate_items_context(relevant_products) \n",
    "\n",
    "    # Construct a prompt including product details and the query. Remember to add the context and the query in the prompt, also, ask the LLM to provide the product ID in the answer\n",
    "    prompt = (\n",
    "    f\"Given the available set of cloth products, answer the question that follows, providing the item ID in your answers. \"\n",
    "    f\"Other information might be provided but not necessarily all of them; pick only the relevant ones for the given query and avoid being too long when describing the items' features. \"\n",
    "    f\"If no number of products is mentioned in the query, select at most five to show. \"\n",
    "    f\"CLOTH PRODUCTS AVAILABLE: {context} \"\n",
    "    f\"QUERY: {query}\"\n",
    "        )\n",
    "    \n",
    "    # Generate kwargs (parameters dict) for parameterized input to the LLM with , Prompt, role = 'assistant' and **parameters_dict\n",
    "    kwargs = generate_params_dict(prompt, role='assistant', **parameters_dict)\n",
    "    \n",
    "    \n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = query_on_products('Make a wonderful look for a man attending a wedding party happening during night.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = query_on_products('Give me three T-shirts for sunny days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5 - The Final Function!\n",
    "\n",
    "---\n",
    "\n",
    "<a id='5-1'></a>\n",
    "### 5.1 The function to rule them all\n",
    "\n",
    "Now it‚Äôs time to bring everything together into a single function!\n",
    "\n",
    "This function will:\n",
    "\n",
    "1. Check if the query is related to an FAQ or a Product.\n",
    "2. If it‚Äôs an FAQ, run the FAQ-related workflow.\n",
    "3. If it‚Äôs a Product, run the Product-related workflow.\n",
    "\n",
    "It returns the kwargs dictionary containing the appropriate arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def answer_query(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Determines the type of a given query (FAQ or Product) and executes the appropriate workflow.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary of keyword arguments to be used for further processing.\n",
    "      If the query is neither FAQ nor Product-related, returns a default response dictionary\n",
    "      instructing the assistant to answer based on existing context.\n",
    "    \"\"\"\n",
    "    label = check_if_faq_or_product(query)\n",
    "    if label not in ['FAQ', 'Product']:\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"prompt\": f\"User provided a question that does not fit FAQ or Product related questions. \"\n",
    "                      f\"Answer it based on the context you already have so far. Query provided by the user: {query}\"\n",
    "        }\n",
    "    if label == 'FAQ':\n",
    "        kwargs = query_on_faq(query)\n",
    "    if label == 'Product':\n",
    "        try:\n",
    "            kwargs = query_on_products(query)\n",
    "        except:\n",
    "            return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"prompt\": f\"User provided a question that broke the querying system. Instruct them to rephrase it.\"\n",
    "                      f\"Answer it based on the context you already have so far. Query provided by the user: {query}\"\n",
    "        }\n",
    "            \n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = answer_query(\"What are your working hours?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5-2'></a>\n",
    "### 5.2 The ChatBot\n",
    "\n",
    "Now you can implement the ChatBot! It is already given to you, as it is not the focus of this course or assignment, but feel free to inspect the utils.py file to understand how it works (and improve it as you wish!)\n",
    "\n",
    "Suggested queries:\n",
    "\n",
    "- Do you have blue t-shirts on your catalogue?\n",
    "- I bought a dress and I didn't like it. How can I get a refund?\n",
    "- I am going to a party at the beach. Can you suggest a nice look for me? It will be a warm night, and I‚Äôm a man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_widget = ChatWidget(generator_function = answer_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You made your ChatBot using RAG techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
